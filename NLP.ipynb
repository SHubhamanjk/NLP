{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzRXerdwlkq4",
        "outputId": "ce42e424-d9a5-4dec-9f79-6b63a144e471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "K4Fs8Nsrl1D3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = \"Hello and welcome friends to NLP workshop. My name is shridhar mankar. I will be teaching you NLP from scratch\""
      ],
      "metadata": {
        "id": "pne9mBj2l2gQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = word_tokenize(a)\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqiBBoNql6Ut",
        "outputId": "b98abea3-c4e0-4d64-e1ee-8a312a7971bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'and',\n",
              " 'welcome',\n",
              " 'friends',\n",
              " 'to',\n",
              " 'NLP',\n",
              " 'workshop',\n",
              " '.',\n",
              " 'My',\n",
              " 'name',\n",
              " 'is',\n",
              " 'shridhar',\n",
              " 'mankar',\n",
              " '.',\n",
              " 'I',\n",
              " 'will',\n",
              " 'be',\n",
              " 'teaching',\n",
              " 'you',\n",
              " 'NLP',\n",
              " 'from',\n",
              " 'scratch']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S = sent_tokenize(a)\n",
        "S"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7TPYrK2mHl0",
        "outputId": "4f51b584-d782-4e44-ba0a-51551454bbad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello and welcome friends to NLP workshop.',\n",
              " 'My name is shridhar mankar.',\n",
              " 'I will be teaching you NLP from scratch']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(A),len(A),len(S)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYcfqtH2mbe6",
        "outputId": "1b0331cc-e888-4cac-c50d-db31185485d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 22, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "frequency = FreqDist()"
      ],
      "metadata": {
        "id": "Z0wqpr7EmgXd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in A:\n",
        " frequency[i] = frequency[i]+1\n",
        "\n",
        "frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dVcGJ8xmj2r",
        "outputId": "7b925900-d9f8-4aad-dfe9-3b489dd573f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'NLP': 2, '.': 2, 'Hello': 1, 'and': 1, 'welcome': 1, 'friends': 1, 'to': 1, 'workshop': 1, 'My': 1, 'name': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()"
      ],
      "metadata": {
        "id": "xkP6jGt-mr1b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pst.stem('Making')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ilj23U8smwHD",
        "outputId": "8bca04e1-3697-4ca5-d880-03fbf23dceed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'make'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in A:\n",
        "    print(pst.stem(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGvQZWgGmyc4",
        "outputId": "67dbab75-6d8b-4cf2-cccd-3fe6c1d0587d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "and\n",
            "welcom\n",
            "friend\n",
            "to\n",
            "nlp\n",
            "workshop\n",
            ".\n",
            "my\n",
            "name\n",
            "is\n",
            "shridhar\n",
            "mankar\n",
            ".\n",
            "i\n",
            "will\n",
            "be\n",
            "teach\n",
            "you\n",
            "nlp\n",
            "from\n",
            "scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdqxE3L1m2Uh",
        "outputId": "b5e9441b-9ec0-4fa2-d66e-d180f8ed181d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "tKlX3218m8LQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pst.stem('trouble')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NSfBvseLm_4C",
        "outputId": "36fbb237-2a29-49f2-889f-aeefd0c0c76a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'troubl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('trouble')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fEDNMWDZnDcN",
        "outputId": "fe22f2ca-8108-4735-cb89-b05059ad5354"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'trouble'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in A:\n",
        "    print(lemmatizer.lemmatize(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kBNQkXdnHU_",
        "outputId": "fbf51b3a-088d-42e9-f3d2-e946411c35dc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "and\n",
            "welcome\n",
            "friend\n",
            "to\n",
            "NLP\n",
            "workshop\n",
            ".\n",
            "My\n",
            "name\n",
            "is\n",
            "shridhar\n",
            "mankar\n",
            ".\n",
            "I\n",
            "will\n",
            "be\n",
            "teaching\n",
            "you\n",
            "NLP\n",
            "from\n",
            "scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for i in A:\n",
        "  for j in A:\n",
        "    if pst.stem(i)==lemmatizer.lemmatize(j):\n",
        "      count=count+1\n",
        "print(count)\n",
        "len(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ASw2tySnKcM",
        "outputId": "cd1a99f9-4c1f-478c-d068-10aa34ecfd5b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVsDsMgwnLkh",
        "outputId": "38e92a32-99ad-4d8b-b3af-e2ea7fcdaeeb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in A:\n",
        " print(nltk.pos_tag([i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmgvwly0nizH",
        "outputId": "743511cd-2dba-43a4-b713-5f3e6ec5a943"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hello', 'NN')]\n",
            "[('and', 'CC')]\n",
            "[('welcome', 'NN')]\n",
            "[('friends', 'NNS')]\n",
            "[('to', 'TO')]\n",
            "[('NLP', 'NN')]\n",
            "[('workshop', 'NN')]\n",
            "[('.', '.')]\n",
            "[('My', 'PRP$')]\n",
            "[('name', 'NN')]\n",
            "[('is', 'VBZ')]\n",
            "[('shridhar', 'NN')]\n",
            "[('mankar', 'NN')]\n",
            "[('.', '.')]\n",
            "[('I', 'PRP')]\n",
            "[('will', 'MD')]\n",
            "[('be', 'VB')]\n",
            "[('teaching', 'VBG')]\n",
            "[('you', 'PRP')]\n",
            "[('NLP', 'NN')]\n",
            "[('from', 'IN')]\n",
            "[('scratch', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niKn0323nkbc",
        "outputId": "658c9837-2050-4a0d-de78-ca7e410450e0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text= '''Harry Lives in New York'''\n",
        "words= word_tokenize(text)\n",
        "postags=pos_tag(words)\n",
        "print(postags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3AYqq5wnqYB",
        "outputId": "334d2a4f-bfd5-4af6-a457-5a65cc8cca5b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Harry', 'NNP'), ('Lives', 'VBZ'), ('in', 'IN'), ('New', 'NNP'), ('York', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = nltk.ne_chunk(postags)\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muHLdn5anxwi",
        "outputId": "144cc8a7-1764-45d1-ea4f-9dd2d4968411"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (PERSON Harry/NNP) Lives/VBZ in/IN (GPE New/NNP York/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text= 'John wants a new Samsung device from Pune'\n",
        "words= word_tokenize(text)\n",
        "postags=pos_tag(words)\n",
        "postags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6TC_A77oApK",
        "outputId": "046ce01f-0970-498d-ed2c-fb9e8d333b04"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('John', 'NNP'),\n",
              " ('wants', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('new', 'JJ'),\n",
              " ('Samsung', 'NNP'),\n",
              " ('device', 'NN'),\n",
              " ('from', 'IN'),\n",
              " ('Pune', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = nltk.ne_chunk(postags)\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgIogYF7oJ8f",
        "outputId": "c2e4e28e-e1a2-4611-9386-3a72f987b3a0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON John/NNP)\n",
            "  wants/VBZ\n",
            "  a/DT\n",
            "  new/JJ\n",
            "  (ORGANIZATION Samsung/NNP)\n",
            "  device/NN\n",
            "  from/IN\n",
            "  (GPE Pune/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bMyZjtEoRjI",
        "outputId": "8deeb46d-ddc4-4b1e-8ad6-bb0240fd9531"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "Q2V9OIXjoVBz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SccDe1Kloci5",
        "outputId": "738a383e-6ed5-49d4-abbb-a76dc0f0f792"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg = \"My name is shridhar mankar, I love making videos and watching kdrama. My speciality is making things easy\"\n",
        "\n",
        "words = word_tokenize(msg)\n",
        "\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in words:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "print(words)\n",
        "print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttm5JbtYohge",
        "outputId": "2fca4ec0-e569-42f0-99f5-77d63046e2df"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'name', 'is', 'shridhar', 'mankar', ',', 'I', 'love', 'making', 'videos', 'and', 'watching', 'kdrama', '.', 'My', 'speciality', 'is', 'making', 'things', 'easy']\n",
            "['My', 'name', 'shridhar', 'mankar', ',', 'I', 'love', 'making', 'videos', 'watching', 'kdrama', '.', 'My', 'speciality', 'making', 'things', 'easy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OOgFEMpkosRF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A1 = 'hello and welcome dosto'\n",
        "A2 = 'shri love NLP'\n",
        "A3 = 'shri is good boy'"
      ],
      "metadata": {
        "id": "XFdpP_buowNU"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "vectors = vectorizer.fit_transform([A1,A2,A3])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "dense = vectors.todense()\n",
        "\n",
        "result = pd.DataFrame(dense, columns=feature_names)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YGLH31doyVY",
        "outputId": "652516dd-0cc0-452d-b405-37270b67fecc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   boy  dosto  good  hello  love  nlp  shri  welcome\n",
            "0    0      1     0      1     0    0     0        1\n",
            "1    0      0     0      0     1    1     1        0\n",
            "2    1      0     1      0     0    0     1        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "lJKzrOvdpUV1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "vectors = vectorizer.fit_transform([A1,A2,A3])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "dense = vectors.todense()\n",
        "\n",
        "result = pd.DataFrame(dense, columns=feature_names)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPL4xUxfpXwx",
        "outputId": "85fcce15-e8ce-4077-cfad-d2cab84731ad"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        boy    dosto      good    hello      love       nlp     shri  welcome\n",
            "0  0.000000  0.57735  0.000000  0.57735  0.000000  0.000000  0.00000  0.57735\n",
            "1  0.000000  0.00000  0.000000  0.00000  0.622766  0.622766  0.47363  0.00000\n",
            "2  0.622766  0.00000  0.622766  0.00000  0.000000  0.000000  0.47363  0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwPNHsU_pftI",
        "outputId": "3c0d19fb-ba52-4744-cc75-0db7c8bca9d2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    }
  ]
}